<!DOCTYPE html>
<html lang="it">
<head>
  <meta charset="UTF-8" />
  <title>WebXR AR Character + Kokoro TTS</title>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: #000;
      font-family: system-ui, sans-serif;
    }
    #overlay {
      position: fixed;
      top: 10px;
      left: 10px;
      padding: 10px 12px;
      background: rgba(0, 0, 0, 0.7);
      color: #fff;
      font-size: 13px;
      border-radius: 6px;
      z-index: 10;
      max-width: 320px;
    }
    #overlay textarea {
      width: 100%;
      min-height: 50px;
      resize: vertical;
      font-family: inherit;
      font-size: 12px;
    }
    #overlay button {
      margin-top: 4px;
      padding: 4px 8px;
      font-size: 12px;
    }
    #overlay select {
      font-size: 12px;
    }
    #status {
      margin-top: 4px;
      font-size: 11px;
      opacity: 0.85;
    }
  </style>

  <!-- Import map per three.js + addons -->
  <script type="importmap">
  {
    "imports": {
      "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
      "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/"
    }
  }
  </script>
</head>
<body>
  <div id="overlay">
    <b>WebXR AR - Random Walk + TTS</b><br>
    • Punta la scrivania finché vedi il cerchio verde.<br>
    • Tocca / premi il trigger per piazzare il personaggio.<br>
    • Lui girerà a caso sulla scrivania.<br>
    • Scrivi un testo e premi “Parla” per farlo parlare.<br>
    <br>
    <textarea id="ttsText">Ciao, sto camminando sulla tua scrivania!</textarea><br>
    Voce:
    <select id="voiceSelect">
      <option value="af_bella">af_bella</option>
      <option value="af_sarah">af_sarah</option>
      <option value="af_sky">af_sky</option>
      <option value="af_heart">af_heart</option>
    </select>
    <button id="speakBtn">Parla</button>
    <div id="status">TTS non inizializzato.</div>
  </div>

  <script type="module">
    import * as THREE from 'three';
    import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
    import { ARButton } from 'three/addons/webxr/ARButton.js';

    // ---- Nomi delle animazioni nel tuo GLB ----
    const ANIMATION_NAMES = {
      idle: 'Idle_Loop',
      walk: 'Walk_Loop',
      run:  'Jog_Fwd_Loop',
    };

    // ---- Riferimenti DOM ----
    const ttsTextEl    = document.getElementById('ttsText');
    const speakBtn     = document.getElementById('speakBtn');
    const voiceSelect  = document.getElementById('voiceSelect');
    const statusEl     = document.getElementById('status');

    // ---- Three.js / WebXR ----
    let camera, scene, renderer;
    let character;
    let mixer;
    const actions = {};
    let currentAction;

    let reticle;
    let hitTestSource = null;
    let hitTestSourceRequested = false;
    let controller;

    const clock = new THREE.Clock();

    // ---- Wander state ----
    let characterPlaced = false;
    let wanderCenter = new THREE.Vector3();
    let wanderRadius = 0.4;    // raggio cerchio sulla scrivania (metri)
    let wanderTarget = null;
    const WALK_SPEED = 0.25;   // m/s

    // ---- Audio 3D / TTS ----
    let listener;
    let voiceAudio;  // THREE.PositionalAudio attaccato al personaggio

    // Kokoro TTS
    let KokoroTTS = null;   // classe
    let ttsModel  = null;   // istanza
    let ttsLoading = false;

    init();
    animate();

    // ------------------------
    // INIT SCENA AR
    // ------------------------
    function init() {
      scene = new THREE.Scene();

      // Camera: AR la sovrascrive ma va creata
      camera = new THREE.PerspectiveCamera(
        70,
        window.innerWidth / window.innerHeight,
        0.01,
        20
      );

      // Luci per il modello virtuale
      const hemiLight = new THREE.HemisphereLight(0xffffff, 0x444444, 0.8);
      scene.add(hemiLight);

      const dirLight = new THREE.DirectionalLight(0xffffff, 0.8);
      dirLight.position.set(1, 2, 1);
      scene.add(dirLight);

      // Renderer
      renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
      renderer.setPixelRatio(window.devicePixelRatio);
      renderer.setSize(window.innerWidth, window.innerHeight);
      renderer.xr.enabled = true;
      document.body.appendChild(renderer.domElement);

      // AR Button
      document.body.appendChild(
        ARButton.createButton(renderer, {
          requiredFeatures: ['hit-test']
        })
      );

      // Reticolo per hit-test
      const ringGeo = new THREE.RingGeometry(0.07, 0.09, 32).rotateX(-Math.PI / 2);
      const ringMat = new THREE.MeshBasicMaterial({
        color: 0x00ff00,
        side: THREE.DoubleSide
      });
      reticle = new THREE.Mesh(ringGeo, ringMat);
      reticle.matrixAutoUpdate = false;
      reticle.visible = false;
      scene.add(reticle);

      // Controller XR (tap/schermata/trigger)
      controller = renderer.xr.getController(0);
      controller.addEventListener('select', onSelect);
      scene.add(controller);

      // Audio listener sulla camera
      listener = new THREE.AudioListener();
      camera.add(listener);

      // Carica il modello GLB
      const loader = new GLTFLoader();
      loader.load(
        'models/character.glb',
        (gltf) => {
          character = gltf.scene;
          character.traverse((obj) => {
            if (obj.isMesh) {
              obj.castShadow = true;
              obj.receiveShadow = true;
            }
          });

          character.visible = false; // diventa visibile dopo il piazzamento
          scene.add(character);

          // Animazioni
          mixer = new THREE.AnimationMixer(character);
          const clips = gltf.animations;
          console.log('Animazioni nel GLB:', clips.map(c => c.name));

          function addAction(label, clipName) {
            const clip = THREE.AnimationClip.findByName(clips, clipName);
            if (clip) {
              actions[label] = mixer.clipAction(clip);
            } else {
              console.warn(`Clip "${clipName}" non trovata nel GLB.`);
            }
          }

          addAction('idle', ANIMATION_NAMES.idle);
          addAction('walk', ANIMATION_NAMES.walk);
          addAction('run',  ANIMATION_NAMES.run);

          if (actions.idle) {
            currentAction = actions.idle;
            currentAction.play();
          } else if (clips[0]) {
            currentAction = mixer.clipAction(clips[0]);
            currentAction.play();
          }

          // Audio posizionale attaccato al personaggio
          voiceAudio = new THREE.PositionalAudio(listener);
          voiceAudio.setRefDistance(0.4);
          voiceAudio.setMaxDistance(4.0);
          voiceAudio.setRolloffFactor(1.0);
          voiceAudio.setDistanceModel('inverse');
          character.add(voiceAudio);
        },
        (xhr) => {
          console.log(`Caricamento GLB: ${(xhr.loaded / xhr.total * 100).toFixed(0)}%`);
        },
        (error) => {
          console.error('Errore caricamento GLB:', error);
        }
      );

      window.addEventListener('resize', onWindowResize);

      // UI: bottone parla
      speakBtn.addEventListener('click', () => {
        speakFromCharacter();
      });
    }

    function onWindowResize() {
      camera.aspect = window.innerWidth / window.innerHeight;
      camera.updateProjectionMatrix();
      renderer.setSize(window.innerWidth, window.innerHeight);
    }

    // ------------------------
    // PIAZZAMENTO PERSONAGGIO
    // ------------------------
    function onSelect() {
      if (!reticle.visible || !character) return;

      const pos = new THREE.Vector3();
      pos.setFromMatrixPosition(reticle.matrix);

      character.position.copy(pos);
      character.scale.set(0.5, 0.5, 0.5); // scala da scrivania
      character.visible = true;

      // Orienta verso la camera
      const camDir = new THREE.Vector3(0, 0, -1).applyQuaternion(camera.quaternion);
      const angle = Math.atan2(camDir.x, camDir.z);
      character.rotation.y = angle;

      // Centro del wander
      wanderCenter.copy(character.position);
      wanderTarget = null;
      characterPlaced = true;

      // Metti subito in walk
      if (actions.walk) {
        switchAction('walk');
      }
    }

    function switchAction(name) {
      const newAction = actions[name];
      if (!newAction || newAction === currentAction) return;

      newAction.reset().play();
      if (currentAction) {
        currentAction.crossFadeTo(newAction, 0.2, false);
      }
      currentAction = newAction;
    }

    // ------------------------
    // RANDOM WALK SULLA SCRIVANIA
    // ------------------------
    function pickNewWanderTarget() {
      if (!characterPlaced) return;

      const angle = Math.random() * Math.PI * 2;
      const radius = wanderRadius * (0.4 + Math.random() * 0.6);

      const target = wanderCenter.clone();
      target.x += Math.cos(angle) * radius;
      target.z += Math.sin(angle) * radius;
      target.y = wanderCenter.y;

      wanderTarget = target;
    }

    function updateWander(delta) {
      if (!characterPlaced || !character) return;

      if (!wanderTarget) {
        pickNewWanderTarget();
        return;
      }

      const pos = character.position;
      const toTarget = new THREE.Vector3().subVectors(wanderTarget, pos);
      const dist = toTarget.length();

      if (dist < 0.02) {
        // ogni tanto idle breve
        if (Math.random() < 0.3 && actions.idle && actions.walk) {
          switchAction('idle');
          setTimeout(() => {
            if (characterPlaced && actions.walk) {
              switchAction('walk');
            }
          }, 1000 + Math.random() * 1500);
        }
        pickNewWanderTarget();
        return;
      }

      toTarget.normalize();

      const angle = Math.atan2(toTarget.x, toTarget.z);
      character.rotation.y = angle;

      const move = WALK_SPEED * delta;
      pos.x += toTarget.x * move;
      pos.z += toTarget.z * move;
      pos.y = wanderCenter.y;
    }

    // ------------------------
    // KOKORO TTS
    // ------------------------
    async function initTTS() {
      if (ttsModel || ttsLoading) return;
      ttsLoading = true;
      statusEl.textContent = 'Carico Kokoro TTS (può volerci un po’ la prima volta)...';

      try {
        // import dinamico dal CDN (build browser di kokoro-js)
        const mod = await import('https://cdn.jsdelivr.net/npm/kokoro-js@1.2.1/dist/kokoro.web.js');
        KokoroTTS = mod.KokoroTTS;

        const model_id = 'onnx-community/Kokoro-82M-v1.0-ONNX';
        ttsModel = await KokoroTTS.from_pretrained(model_id, {
          dtype: 'q8',     // fp32, fp16, q8, q4, q4f16
          device: 'wasm',  // "wasm" o "webgpu" (se supportato)
        });

        statusEl.textContent = 'TTS pronto. Scrivi qualcosa e premi "Parla".';
      } catch (err) {
        console.error('Errore init KokoroTTS', err);
        statusEl.textContent = 'Errore caricando Kokoro TTS (vedi console).';
      } finally {
        ttsLoading = false;
      }
    }

    async function speakFromCharacter() {
      const text = (ttsTextEl.value || '').trim();
      if (!text || !characterPlaced || !voiceAudio) {
        if (!characterPlaced) {
          statusEl.textContent = 'Piazza prima il personaggio sulla scrivania.';
        }
        return;
      }

      if (!ttsModel) {
        await initTTS();
        if (!ttsModel) return;
      }

      const voice = voiceSelect.value;
      statusEl.textContent = 'Generazione audio con Kokoro...';

      try {
        // 1) genera audio
        const audio = await ttsModel.generate(text, { voice });  // audio API kokoro-js 
        const wavBuffer = audio.toWav(); // ArrayBuffer WAV

        // 2) decode in AudioBuffer del Web Audio
        const audioContext = listener.context;
        const copy = wavBuffer.slice(0);

        const audioBuffer = await new Promise((resolve, reject) => {
          audioContext.decodeAudioData(
            copy,
            decoded => resolve(decoded),
            err => reject(err)
          );
        });

        // 3) usa come buffer del PositionalAudio
        voiceAudio.stop(); // ferma eventuale audio in corso
        voiceAudio.setBuffer(audioBuffer);
        voiceAudio.setLoop(false);
        voiceAudio.setVolume(1.0);

        // a volte il context è sospeso finché non c'è input utente, assicuriamoci
        if (audioContext.state === 'suspended') {
          await audioContext.resume();
        }

        voiceAudio.play();
        statusEl.textContent = `Parlando con voce "${voice}".`;
      } catch (err) {
        console.error('Errore TTS/play', err);
        statusEl.textContent = 'Errore durante la generazione o riproduzione audio (vedi console).';
      }
    }

    // ------------------------
    // ANIMATE / RENDER LOOP
    // ------------------------
    function animate() {
      renderer.setAnimationLoop(renderXR);
    }

    function renderXR(timestamp, frame) {
      const delta = clock.getDelta();

      if (mixer) mixer.update(delta);
      updateWander(delta);

      if (frame) {
        const referenceSpace = renderer.xr.getReferenceSpace();
        const session = renderer.xr.getSession();

        if (!hitTestSourceRequested) {
          session.requestReferenceSpace('viewer').then((refSpace) => {
            session.requestHitTestSource({ space: refSpace }).then((source) => {
              hitTestSource = source;
            });
          });

          session.addEventListener('end', () => {
            hitTestSourceRequested = false;
            hitTestSource = null;
          });

          hitTestSourceRequested = true;
        }

        if (hitTestSource) {
          const hitTestResults = frame.getHitTestResults(hitTestSource);

          if (hitTestResults.length > 0) {
            const hit = hitTestResults[0];
            const pose = hit.getPose(referenceSpace);

            reticle.visible = true;
            reticle.matrix.fromArray(pose.transform.matrix);
          } else {
            reticle.visible = false;
          }
        }
      }

      renderer.render(scene, camera);
    }
  </script>
</body>
</html>
